{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Arbres de décision et fôrets aléatoires\n",
    "\n",
    "\n",
    "## Résumé\n",
    "\n",
    "Un arbre de décision est un modèle de classification hiérarchique : à chaque noeud de l'arbre\n",
    "est associé un test sur une des dimensions $x_i$ de la forme $x_i \\{\\leq,~ >,~ = \\} s$ ($s$ une valeur réelle) qui indique le noeud fils qui doit être sélectionné (par exemple pour un arbre binaire, le fils gauche quand le test est vrai, le fils droit sinon). A chaque feuille de l'arbre est associée une étiquette. Ainsi, la classification d'un exemple consiste en une succession de tests sur les valeurs des dimensions de l'exemple, selon un chemin dans l'arbre de la racine à une des feuilles. La feuille atteinte donne la classe prédite.\n",
    "\n",
    "L'apprentissage de l'arbre s'effectue de manière récursive top-down : à chaque noeud, l'algorithme choisit le split vertical (seuillage\n",
    "d'une variable) qui optimise une mesure d'homogénéité sur la partition obtenue (usuellement l'[entropie de shanon](http://fr.wikipedia.org/wiki/Entropie_de_Shannon#D.C3.A9finition_formelle) ou l'[index de Gini](http://fr.wikipedia.org/wiki/Coefficient_de_Gini) : l'entropie d'une partition est d'autant plus petite qu'une classe prédomine dans chaque sous-\n",
    "ensemble de la partition, elle est nulle lorsque la séparation est parfaite).\n",
    "\n",
    "Bien que l'algorithme pourrait continuer récursivement jusqu'à n'obtenir que des feuilles contenant un ensemble pur d'exemples (d'une seule classe), on utilise souvent des critères d'arrêts (pourquoi ? - nous y reviendrons lors de ce TP). Les plus communs sont les suivants :\n",
    "\n",
    "+ le nombre d'exemples minimum que doit contenir un noeud\n",
    "\n",
    "+ la profondeur maximale de l'arbre\n",
    "\n",
    "+ la différence de gain de la mesure d'homogénéité entre le noeud père et les noeuds fils\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prise en main sklearn, données artificielles\n",
    "scikit-learn est un des modules de machine learning les plus populaires (installation : pip install scikit-learn --user).\n",
    "Il contient les algos que nous avons déjà vu (knn, noyaux, perceptron, regression), et bien d'autres outils et algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # module pour les outils mathématiques\n",
    "import matplotlib.pyplot as plt # module pour les outils graphiques\n",
    "import tools # module fourni en TP1\n",
    "from sklearn import tree # module pour les arbres\n",
    "from sklearn import ensemble # module pour les forets\n",
    "from sklearn import cross_validation as cv\n",
    "from IPython.display import Image\n",
    "import pydot\n",
    "\n",
    "#que pour jupyter  !!\n",
    "%matplotlib inline import numpy as np # module pour les outils mathématiques\n",
    "import matplotlib.pyplot as plt # module pour les outils graphiques\n",
    "import tools # module fourni en TP1\n",
    "from sklearn import tree # module pour les arbres\n",
    "from sklearn import ensemble # module pour les forets\n",
    "from sklearn import cross_validation as cv\n",
    "from IPython.display import Image\n",
    "import pydot\n",
    "\n",
    "#que pour jupyter  !!\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les modeles d'apprentissage sous scikit fonctionnent de la manière suivante :\n",
    "\n",
    "+ création du classifieur (ici  **cls=Classifier()**)\n",
    "\n",
    "+ réglage des paramètres (par exemple la profondeur maximale, le nombre d'exemples par noeud)\n",
    "\n",
    "+ apprentissage du classifieur par l'intermédiaire de la fonction **cls.fit(data,labels)** \n",
    "\n",
    "+ prediction pour de nouveaux exemples : fonction **cls.predict(data)**\n",
    "\n",
    "+ score du classifieur (précision, pourcentage d'exemples bien classés) : fonction **cls.score(data,labels)**\n",
    "\n",
    "Pour un arbre de décision, la classe est **tree.DecisionTreeClassfier()**.\n",
    "Dans le cas des arbres de décisions, nous avons aussi la possibilité d'obtenir l'importance des variables, un score qui est d'autant plus grand que la variable est \"utile\" pour la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialisation\n",
    "data,y=tools.gen_arti()\n",
    "mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "mytree.max_depth=8 #profondeur maximale de 5\n",
    "mytree.min_samples_split=1 #nombre minimal d'exemples dans une feuille\n",
    "#Apprentissage\n",
    "mytree.fit(data,y)\n",
    "\n",
    "#prediction\n",
    "pred=mytree.predict(data)\n",
    "print \"precision : \", (1.*pred!=y).sum()/len(y)\n",
    "\n",
    "#ou directement pour la precision : \n",
    "print \"precision (score) : \"  +` mytree.score(data,y)`\n",
    "\n",
    "#Importance des variables :\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar([1,2],mytree.feature_importances_)\n",
    "plt.title(\"Importance Variable\")\n",
    "plt.xticks([1,2],[\"x1\",\"x2\"])\n",
    "\n",
    "#Affichage de l'arbre\n",
    "with file(\"mytree.dot\",\"wb\") as f:\n",
    "    tree.export_graphviz(mytree,f)\n",
    "\n",
    "###### Si graphviz n'est pas installe, la fonction suivante permet d'afficher un arbre\n",
    "def affiche_arbre(tree):\n",
    "    long = 10\n",
    "    sep1=\"|\"+\"-\"*(long-1)\n",
    "    sepl=\"|\"+\" \"*(long-1)\n",
    "    sepr=\" \"*long\n",
    "    def aux(node,sep):\n",
    "        if tree.tree_.children_left[node]<0:\n",
    "            ls =\"(%s)\" % (\", \".join( \"%s: %d\" %(tree.classes_[i],int(x)) for i,x\n",
    " in enumerate(tree.tree_.value[node].flat)))\n",
    "            return sep+sep1+\"%s\\n\" % (ls,)\n",
    "        return (sep+sep1+\"X%d<=%0.2f\\n\"+\"%s\"+sep+sep1+\"X%d>%0.2f\\n\"+\"%s\" )% \\\n",
    "                    (tree.tree_.feature[node],tree.tree_.threshold[node],aux(tree.tree_.children_left[node],sep+sepl),\n",
    "                    tree.tree_.feature[node],tree.tree_.threshold[node],aux(tree.tree_.children_right[node],sep+sepr))\n",
    "    return aux(0,\"\")\n",
    "print(affiche_arbre(mytree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur différents jeux de données artificielles (des tps précédents) : \n",
    "\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'>observer les frontières de décision en fonction de la taille de l'arbe.</font>*\n",
    "\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'>faites varier les différents paramètres disponibles (hauteur de l'arbre, nombre d'exemples dans les noeuds par exemple) et tracer la précision en fonction de ces paramètres.\n",
    "Que remarquez vous sur la précision ?</font>*\n",
    "\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'>Est-ce que cette valeur de précision vous semble une estimation fiable de l'erreur ? Pourquoi ?</font>*\n",
    "\n",
    "## Validation croisée : sélection de modèle\n",
    "\n",
    "Il est rare de disposer en pratique d'un ensemble de test (on préfère inclure le plus grand\n",
    "nombre de données dans l'ensemble d'apprentissage). Pour sélectionner un modèle tout en considérant le plus grand nombre d'exemples possible pour l'apprentissage, on utilise généralement\n",
    "une procédure dite de sélection par validation croisée. Pour chaque paramètrisation du problème,\n",
    "une estimation de l'erreur empirique du classifieur appris est faîte selon la procédure suivante :\n",
    "\n",
    "+ l'ensemble d'apprentissage $E_{app}$ est partitioné en $n$ ensembles d'apprentissage $\\{E_i\\}$\n",
    "\n",
    "+ Pour $i=1..n$\n",
    "\n",
    "  + l'arbre est appris sur $E_{app}$\\ $E_i$\n",
    "\n",
    "  + l'erreur en test $err(E_i)$ est évaluée sur $E_i$ (qui n'a pas servi à l'apprentissage à cette itération)\n",
    "\n",
    "+ l'erreur moyenne $err=\\frac{1}{n}\\sum_{i=1}^n err(E_i)$ est calculée, le modèle sélectionné est celui qui minimise cette erreur\n",
    "\n",
    "\n",
    "Ci-dessous quelques fonctions utiles pour la sélection de modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#permet de partager un ensemble en deux ensembles d'apprentissage et de test \n",
    "data_train,data_test,y_train,y_test=cv.train_test_split(data,y,test_size=0.3)\n",
    "mytree.fit(data_train,y_train)\n",
    "print \"precision en test (split 30 %) : \", mytree.score(data_test,y_test)\n",
    "\n",
    "#permet d'executer une n-validation croisée et d'obtenir le score pour chaque tentative\n",
    "print \"precision en test (10-fold validation) : \",cv.cross_val_score(mytree,data,y,cv=10)\n",
    "\n",
    "#alternative : obtenir les indices et itérer dessus  \n",
    "kf= cv.KFold(y.size,n_folds=10)\n",
    "res_train=[]\n",
    "res_test=[]\n",
    "for cvtrain,cvtest in kf:\n",
    "    mytree.fit(data[cvtrain],y[cvtrain])\n",
    "    res_train+=[mytree.score(data[cvtrain],y[cvtrain])]\n",
    "    res_test+=[mytree.score(data[cvtest],y[cvtest])]\n",
    "print \"ou de maniere analogue : \"\n",
    "print \"precision en train : \",res_train\n",
    "print \"precision en test : \",res_test\n",
    "print \"moyenne train : \",np.mean(res_train),\" (\", np.std(res_train),\")\"             \n",
    "print \"moyenne test : \",np.mean(res_test),\" (\",np.std(res_test),\")\"\n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<font style=\"BACKGROUND-COLOR: lightgray\" color='red'>Manipuler sur les différents types de génération artificielle ces fonctions afin de trouver les meilleurs paramètres selon le problème. Tracer l'erreur d'apprentissage et l'erreur de test en fonction des paramètres étudiés. Que se passe-t-il pour des profondeurs trop élevées des arbres ?</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification données USPS\n",
    "\n",
    "Tester sur les données USPS (en sélectionnant quelques sous-classes). Observer l'importance des variables. Afficher la matrice 2D de la variable importance de chaque pixel de l'image (avec **plt.imshow(matrix)**). Les résultats semble-t-ils cohérents ? \n",
    "Utiliser l'algorithme du perceptron fourni par sklearn (**linear_model.Perceptron**) ou le votre et comparer les résultats obtenus pour les poids.\n",
    "\n",
    "Sur quelques exemples, comparer les performances des arbres et du Perceptron en utilisant la validation croisée pour calibrer au mieux vos modèles. \n",
    "\n",
    "Expérimenter également les fôrets aléatoires : c'est une méthode de baging très utilisée, qui consiste à considérer un ensemble d'arbres appris chacun sur un échantillonage aléatoire de la base d'exemples; la classification se fait par vote majoritaire (**enemble.RandomForestClassifier()**).\n",
    "\n",
    "\n",
    "## Classification sur la base movielens \n",
    "\n",
    "La base movielens est une base de données issue d'imdb, qui contient des informations sur des films (le genre, l'année de production, des tags) et des notes attribuées par les utilisateurs. Elle est utilisée généralement pour la recommendation de films. Nous allons l'utiliser dans le cadre de la classification, afin de prédire si un film est bon ou mauvais, dans deux contextes :\n",
    "\n",
    "+ en prenant en compte uniquement l'information sur le film et le score moyen du film\n",
    "\n",
    "+ en prenant en compte l'information de l'utilisateur qui score le film\n",
    "\n",
    "Télécharger l'[archive suivante](http://www-connex.lip6.fr/~baskiotisn/ARF15/imdb_extrait.pkl)\n",
    "\n",
    "Le bloc de code suivant est utilisé pour  charger et prétraiter les données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "[data,id2titles, fields]=cPickle.load(file(\"imdb_extrait.pkl\"))\n",
    "datax = data[:,:32]\n",
    "datay= np.array([1 if x[33]>6.5 else -1 for x in data]) # seuil de bon film a 6.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les informations suivantes sont stockées :\n",
    "\n",
    "+ fields : liste des champs utilisés (28 genres, durée, couleur ou noir/blanc, année, budget,nombre de votes et rating)\n",
    "\n",
    "+ data : une matrice, chaque ligne un film, chaque colonne un champs, 1 indique le genre s'applique au film, 0 non.\n",
    "\n",
    "+ id2titles : pour chaque index de film, le titre du film\n",
    "\n",
    "### Classification à partir de l'information unique du film\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'> Expérimenter les arbres de décisions et le perceptron pour cette tâche. L'ordre de grandeur de chaque dimension joue-t-il un role ? sur quelles dimensions cela peut poser problème ? </font>*\n",
    "\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'> Sur quelques paramètres, que remarquez vous sur l'erreur d'apprentissage et de test ?</font>*\n",
    "\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'> La taille de l'ensemble de test joue-t-elle un rôle ?</font>*\n",
    "\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'> Tracer les courbes de ces deux erreurs en fonction de la profondeur. Que remarquez vous ? Quels sont les meilleurs paramètres pour l'erreur en apprentissage et en test ?</font>*\n",
    "\n",
    "+ *<font style=\"BACKGROUND-COLOR: lightgray\" color='red'> Quelles sont les variables les plus importantes ?  </font>*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
